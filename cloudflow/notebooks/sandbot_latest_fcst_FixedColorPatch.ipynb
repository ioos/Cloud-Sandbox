{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import glob\n",
    "from datetime import datetime\n",
    "\n",
    "import boto3\n",
    "import cmocean\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from xarray import open_mfdataset\n",
    "\n",
    "from cloudflow.services.S3Storage import S3Storage\n",
    "from cloudflow.job.Plotting import Plotting\n",
    "from cloudflow.utils import romsUtil as utils\n",
    "\n",
    "DEBUG = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_indexhtml(indexfile : str, imagelist : list):\n",
    "\n",
    "    htmlhead = '''<html xmlns=\"http://www.w3.org/1999/xhtml\">\n",
    "                  <meta http-equiv=\"Cache-control\" content=\"no-cache\">\n",
    "                  <head>\n",
    "                  <title>Cloud-Sandbot</title>\n",
    "                  </head>'''\n",
    "\n",
    "    htmlbody = '<body>\\n'\n",
    "    for image in imagelist:\n",
    "       imagehtml = f'<img src=\"{image}\">\\n'\n",
    "       htmlbody += imagehtml\n",
    "\n",
    "    htmlbody += '</body>\\n'\n",
    "    html = f'''{htmlhead}\n",
    "               {htmlbody}\n",
    "               </html>'''\n",
    "\n",
    "    with open(indexfile, 'w') as index:\n",
    "        index.write(html) \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roms_nosofs(COMDIR: str, OFS: str, HH: str):\n",
    "    \"\"\"Load ROMS NOSOFS dataset\"\"\"\n",
    "\n",
    "    filespec = f'{COMDIR}/nos.{OFS}.fields.f00*.t{HH}z.nc'\n",
    "    print(f'filespec is: {filespec}')\n",
    "    return open_mfdataset(filespec, decode_times=False, combine='by_coords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fvcom_nosofs(COMDIR: str, OFS: str, HH: str):\n",
    "    \"\"\"Load FVCOM NOSOFS dataset\"\"\"\n",
    "\n",
    "    from netCDF4 import MFDataset\n",
    "\n",
    "    filespec = f'{COMDIR}/nos.{OFS}.fields.f00*.t{HH}z.nc'\n",
    "    print(f'filespec is: {filespec}')\n",
    "    return MFDataset(filespec)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dsofs_latest(COMROT: str='/com/nos'):\n",
    "    \"\"\" Load the most recent OFS forecast available on COMROT \"\"\"\n",
    "    \n",
    "    # List the directories in COMROT that match [a-z]*ofs.YYYYMMDDHH\n",
    "    regex = \"[a-z]*ofs.*[0-1][0-9][0-3][0-9][0-9][0-9]\"\n",
    "    dirs = glob.glob(f'{COMROT}/{regex}')\n",
    "    \n",
    "    if DEBUG: \n",
    "        print ('dirs: ', dirs)\n",
    "    \n",
    "    # Find the one that has the most recent forecast date (do not use modification time?)\n",
    "    # But what if there are two different forecasts for the same date? (use modification time)\n",
    "    dates = []\n",
    "    newest='1900010100'\n",
    "    comdir=dirs[0]\n",
    "    \n",
    "    for path in dirs:\n",
    "        #print(path.split('.'))\n",
    "        date = path.split('.')[-1]\n",
    "        if date > newest:\n",
    "            newest = date\n",
    "            comdir = path          \n",
    "            \n",
    "        dates.append(date)\n",
    "\n",
    "    if DEBUG:\n",
    "        #print('dates : ', dates)\n",
    "        #print('newest: ', newest)\n",
    "        print('comdir: ', comdir)\n",
    "        \n",
    "    # Use the folder name to discover OFS, CDATE, HH\n",
    "    ofs = comdir.split('.')[0].split('/')[-1]\n",
    "    print(ofs)\n",
    "    CDATE = newest[0:8]\n",
    "    HH = newest[8:10]\n",
    "    print(CDATE)\n",
    "    print(HH)\n",
    "    \n",
    "    COMDIR = comdir\n",
    "    OFS = ofs\n",
    "    print(COMDIR)\n",
    "    \n",
    "    if DEBUG: # Only grab first 0-9 hours. Faster!\n",
    "        filespec = f'{COMDIR}/nos.{OFS}.fields.f00*.t{HH}z.nc'\n",
    "    else: # Grab all hours\n",
    "        filespec = f'{COMDIR}/nos.{OFS}.fields.f*.t{HH}z.nc'\n",
    "        \n",
    "    print(f'filespec is: {filespec}')\n",
    "    \n",
    "    if OFS in utils.roms_models:\n",
    "        return open_mfdataset(filespec, decode_times=False, combine='by_coords')\n",
    "    elif OFS in utils.fvcom_models:\n",
    "        return MFDataset(filespec)\n",
    "    else:\n",
    "        print(f\"ERROR: model not recognized: {OFS}\")\n",
    "        return None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing\n",
    "#dsofs_latest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_rho(ds, variable, s3upload=False) -> str:\n",
    "    \n",
    "    if variable == 'zeta':\n",
    "        da = ds[variable].isel(ocean_time=0)\n",
    "        cmap = cmocean.cm.phase\n",
    "    if variable == 'temp':\n",
    "        da = ds[variable].isel(ocean_time=0, s_rho=0)\n",
    "        cmap = cmocean.cm.thermal\n",
    "    if variable == 'salt':\n",
    "        da = ds[variable].isel(ocean_time=0, s_rho=0)\n",
    "        cmap = cmocean.cm.haline\n",
    "    if variable == 'oxygen':\n",
    "        da = ds[variable].isel(ocean_time=0, s_rho=0)\n",
    "        cmap = cmocean.cm.oxy\n",
    "    if variable == 'Pair':\n",
    "        da = ds[variable].isel(ocean_time=0)\n",
    "        cmap = cmocean.cm.diff\n",
    "      \n",
    "    fig = plt.figure(figsize=(12,5))\n",
    "    ax = fig.add_axes([0,0,1,1], projection=ccrs.PlateCarree())\n",
    "    \n",
    "    vari = da.values\n",
    "    vari[np.where(ds.mask_rho==0)]=np.nan\n",
    "\n",
    "    im = ax.contourf(da.lon_rho, da.lat_rho, vari,\n",
    "                     transform=ccrs.PlateCarree(), \n",
    "                     cmap=cmap)\n",
    "    \n",
    "    coast_10m = cfeature.NaturalEarthFeature(\n",
    "        'physical', 'land', '10m',\n",
    "        edgecolor='k', facecolor='0.8'\n",
    "    )\n",
    "    ax.add_feature(coast_10m);\n",
    "    \n",
    "    title = ds.attrs['title']\n",
    "    history = ds.history\n",
    "    now = datetime.now().strftime(\"%m/%d/%Y, %H:%M:%S\")\n",
    "    print(now)\n",
    "    ax.set_title(f\"Image generated on {now}\\n\\n{title}\\n{history}\");\n",
    "    \n",
    "    cbar = fig.colorbar(im, ax=ax)\n",
    "    long_name = da.attrs['long_name']\n",
    "    if variable != 'salt':\n",
    "        units = da.attrs['units']\n",
    "        cbar.set_label(f'{long_name} ({units})')\n",
    "    else:\n",
    "        cbar.set_label(f'{long_name}')\n",
    "    \n",
    "    indexfile = f'docs/index.html'\n",
    "    outfile = f'docs/{variable}.png'\n",
    "    \n",
    "    if not os.path.exists('./docs'):\n",
    "        os.makedirs('./docs')\n",
    "\n",
    "    imagename = outfile.split('/')[-1]\n",
    "\n",
    "    plt.savefig(outfile, bbox_inches='tight')\n",
    "             \n",
    "    if s3upload:\n",
    "        s3 = S3Storage()\n",
    "        bucket = 'ioos-cloud-www'\n",
    "        s3.uploadFile(outfile, bucket, f'{variable}.png', public = True)\n",
    "\n",
    "    return imagename\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    ds_ofs = dsofs_latest()\n",
    "    \n",
    "    indexfile = f'docs/index.html'\n",
    "    if not os.path.exists('./docs'):\n",
    "        os.makedirs('./docs')\n",
    "\n",
    "    bucket = 'ioos-cloud-www'\n",
    "\n",
    "    storageService = S3Storage()\n",
    "\n",
    "    rho_vars = ['temp',\"zeta\", \"salt\" ]\n",
    "\n",
    "    imagelist = []\n",
    "\n",
    "    for var in rho_vars:\n",
    "        imagename = plot_rho(ds_ofs, var, s3upload=True)\n",
    "        imagelist.append(imagename)\n",
    "\n",
    "    make_indexhtml(indexfile, imagelist)\n",
    "    storageService.uploadFile(indexfile, bucket, 'index.html', public=True, text=True)\n",
    "    \n",
    "    print('Finished ...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cloudflow.workflows import flows\n",
    "\n",
    "flows.inject_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
