
**Current caveats to the model suites within the template workflow**

1. ROMS has been precompiled only to use OPENMP option for parallelization due to compiler version dependencies (intel-openmpi) on the Cloud-Sandbox head node. This may suffer some slight computational performance but is still scalable over the hpc node instances.
2. FVCOM version 4.5 has been compiled within the Cloud-Sandbox head node, which is a few versions behind the master branch (version 5.1). This is directly due to the fact that the ADCIRC community has not updated their database to reflect compatible test cases within their latest version of the master branch.  We've had to do some significant work to just get an FVCOM test case to even work properly and serve as a template for modelers.
3. FVCOM model can only work on hpc6id node instances currently due to its architecture (intel x64), which was specifically used to compile its third-party library dependency called METIS through the intel-openmpi compiler. This is an ongoing issue with the METIS library that has to be resolved by the community for architecture compatibility.
4. NWM WRF-Hydro model can only utilize up to 480 cores from hpc node instances at a time before the model breaks due to a netcdf I/O error within its parallelization scheme. This is only specific to AWS node instances for this model as this behavior has not been reflected on other NOAA supercomputers in the past (Hera, WCOSS2). Ongoing efforts will be underway to hopefully resolve this scalability issue for AWS cloud computing specific for this model.
5. Large SCHISM meshes request significant memory allocation for cores within AWS node instances, which will constrain users at times to only utilize the x2idn node instances (more GBS/core of RAM). Users will likely have to evaluate their utilization of SCHISM model configurations between hpc6a and x2idn node instances within the Cloud-Sandbox AWS configuration files. 
